# Java内存模型
一些重要概念
- Java内存模型（JMM）
- 重排序和顺序一致性
- 同步原语（Atomic Operation）	
	- 功能
	- 内存语义

# Java内存模型的基础
**并发中的两大问题**：
- 线程之间如何通信
	- 共享内存：通过写-读内存中的公共状态进行**隐式**通信
	- 消息传递：线程之间必须通过发送消息来**显式**进行通信
- 线程如何同步：同步指的是 **控制不同线程间操作发生相对顺序的机制**



**Java内存模型（JMM）的抽象结构**
Q: 什么是Java内存模型（JMM）?
A: 
**定义线程和主存之间的抽象关系**
JMM屏蔽了不同硬件和操作系统访问内存的差异
- 每个线程都有一个私有的本地内存（Local Memory），本地内存中存储了该线程以读/写共享变量的副本。本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优
化。
- JMM通过控制**主内存**与每个线程的**本地内存**之间的交互，提供内存可见性的保证。

**理解JVM和JMM**
- JVM是一个操作系统，执行指令
- JMM是JVM的一种规范，JMM规定JVM怎么工作

> 补充：
**JVM内存**：
- JVM堆：
- JVM栈：
- 本地方法栈
- 方法区
- 程序计数器

```
线程A <------> 本地内存A（共享变量的副本）<-------> 主存（包含各个共享变量）
				       						↑  					↑
				  						**JMM控制**          共享变量...		
				       						↓					↓
线程B <------> 本地内存B（共享变量的副本）<-------> 主存（包含各个共享变量）
```
线程之间的通信，逻辑上看是线程A向线程B发送消息，但实际流程是：
1. 线程A把本地内存A中更新过的共享变量刷新到主内存中去。
2. 线程B到主内存中去读取线程A之前已更新过的共享变量。


# 重排序和顺序一致性
重排序是指**编译器**和**处理器**为了**优化**程序性能而对**指令序列**进行**重新排序**的一种手段。
JMM为了防止处理器乱改，会在编译的时候插入内存屏障（Memory Barriers），禁止某些处理器重排序
有三种重排序：
- 编译器：
	- 编译器优化重排序：重新安排语句执行顺序
- 处理器：
	- 指令级并行的重排序：指令不一定按照编译的执行，处理器改变指令的执行顺序
	- 内存系统的重排序：处理器的缓存和缓冲区改变指令执行的顺序

一些概念：数据依赖性，as-if-serial，顺序一致性，happens-before
- **数据依赖性**：如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性。
	- 为什么强调数据依赖性：可能发生重排序，重排序必须遵守数据依赖性。即不能改变两个操作的执行顺序，否则执行结构可能被改变
- **as-if-serial语义**：就是可序列化
- **顺序一致性模型**和**顺序一致性** (sequential consistency)
	- 顺序一致性内存模型，是一个理论模型。
	在该模型中，只有一个全局内存，且每次只有一个线程能访问，且按照程序的顺序来执行。
	- 顺序一致性：程序执行结果与顺序一致性模型中执行结果相同
- happens-before：happens-before仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前（the first is visible to and ordered before the second）。


# 同步原语的内存语义
- 同步原语：``synchronized``，``volatile``，``final`` 
	- Atomic Operation
	- synchronized 是隐式锁，悲观锁

## volatile的内存语义
volatile声明的变量读/写会变得特别。
**记忆方法：使用同一个锁对某个变量读/写操作同步**

```java
// 注意vl++是复合操作，包括
class VolatileFeaturesExample {
	volatile long vl = 0L; 		// 使用volatile声明64位的long型变量
	public void set(long l) {
		vl = l; 				// 单个volatile变量的写，原子性
	}
	
	public void getAndIncrement () {
		vl++; 					// 复合（多个）volatile变量的读/写。该方法不是原子性的，需要结合atomic类。
	}
	
	public long get() {
		return vl; 				// 单个volatile变量的读，原子性
	}
}

// 等价于给set和get方法加锁
class VolatileFeaturesExample {
	long vl = 0L; // 64位的long型普通变量
	public synchronized void set(long l) {	// 对单个的普通变量的写用同一个锁同步
		vl = l;
	}

	public void getAndIncrement () { 		// 普通方法调用
		long temp = get(); 					// 调用已同步的读方法
		temp += 1L; 						// 普通写操作
		set(temp);							// 调用已同步的写方法
	}

	public synchronized long get() { 		// 对单个的普通变量的读用同一个锁同步
		return vl;
	}
}
```
这个例子表明：
- volatile变量的读写，看成是锁对**单个**读/写操作做同步
	- 不保证原子性：volatile变量单个读写具有原子性/符合操作如volatile++不具有原子性
	- 可见性：对一个volatile的读，总能看到任意线程对这个volatile变量最后的写入

从内存的角度上volatile的功能，即volatile内存语义。
说白了就是写直接写到主存，读直接从主存读。免得主存和本地内存对不上出问题。
- volatile写和锁的释放有相同的内存语义，JMM会把该线程对应的本地内存中的共享变量值刷新到主内存
- volatile读和锁的获取有相同的内存语义，JMM会把该线程对应的本地内存置为无效。线程接下来将**从主内存中**读取共享变量。

如何实现volatile的内存语义：控制**重排**
控制重排通过编译器生成指令时插入**内存屏障**
（书上的图画的不错，volatile关键字限制了哪些情况下不能重排）

> 不保证原子性： volatile++ 问题可以通过 atomic 类解决


## 锁的内存语义
Java中的锁：
- Java并发编程中的 **同步机制**，**互斥机制**
- 临界区互斥执行
- 释放锁的线程向获取锁的同一个线程发送消息

锁的内存语义，volatile中说过了volatile的读写和锁的获取/释放有相同的内存语义。
- 当线程释放锁时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存中。
- 当线程获取锁时，JMM会把该线程对应的本地内存置为无效。从而使得被监视器保护的临界区代码必须从主内存中读取共享变量。

锁的内存语义的实现 （涉及到**AQS**和**CAS**）
根据``concurrent``包的结构我们知道锁的实现基于 AQS(AbstractQueuedSynchronizer, 同步器框架)
AQS又基于volatile变量和CAS操作

书中分析了 ReentryLock 类的公平锁和非公平锁
- 释放要写volatile变量state
- 获取锁：读或者更新(CAS操作) volatile变量


## final的内存语义
final 域的重排序规则（很绕口，看读写细节）
- 在构造函数内对一个final域的写入，与随后把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。
- 初次读一个包含final域的对象的引用，与随后初次读这个final域，这两个操作之间不能重排序。

写final域的重排序规则
- 写final域的重排序规则禁止把final域的写重排序到构造函数之外
	- JMM禁止编译器把final域的写重排序到构造函数之外。
	- 编译器会在final域的写之后，构造函数return之前，插入一个StoreStore屏障。这个屏障禁止处理器把final域的写重排序到构造函数之外。

读final域的重排序规则
- 在一个线程中，初次读对象引用与初次读该对象包含的final域，JMM禁止处理器重排序这两个操作（注意，这个规则仅仅针对处理器）。编译器会在读final域操作的前面插入一个LoadLoad屏障。

一个构造，读写方法的示例
```java
public class FinalExample {
	int i;　　　　　　　　　		// 普通变量
	final int j;　　　　　　		// final变量
	static FinalExample obj;
	
	public FinalExample () {　　 		// 构造函数
		i = 1;　　　　　　　　 			// 写普通域
		j = 2;　　　　　　　　 			// 写final域
	}

	public static void writer () {　 // 写线程A执行
		obj = new FinalExample ();
	}

	public static void reader () {　 // 读线程B执行
		FinalExample object = obj; 	// 读对象引用
		int a = object.i;　　　　　	// 读普通域
		int b = object.j;　　　　　 // 读final域
	}
}
```

Q: 没看懂，说人话
A: 
写final域的重排序规则：写final域一定发生在构造函数中
``j = 2;``一定在构造时完成，``i = 1;``则不一定，有可能被其他线程插队。

读final域的重排序规则：先读对象，再读对象的final域
``FinalExample object = obj``一定发生在``int b = object.j;``之前（不会被重排），而``int a = object.i;``则不一定。

final 语义在处理器中的实现
阻止重排序，和其他原语一样，通过内存屏障 StoreStore和LoadLoad来实现
X86情况特殊，本身就不会对有依赖关系和写写操作重排序，所以不需要内存屏障

## ``concurrent``包的实现
（原来在锁的内存语义中，我觉得挺重要的单独拿出来）
``concurrent``包的实现基于：**CAS**，**volatile**变量的读/写
``concurrent``包的结构：

```
		volatile变量的读/写    CAS
					| |
					 ↓
AQS(队列同步器)   非阻塞数据结构   原子变量
					| |
					 ↓
Lock 同步器  阻塞队列 Executor 并发容器
```

实现细节：
- 声明共享变量为volatile
- 使用CAS的原子条件**更新**来实现线程之间的同步（CAS同事具有）


# happens-before
定义：
1. 如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。
2. 两个操作之间存在happens-before关系，并不意味着Java平台的具体实现必须要按照happens-before关系指定的顺序来执行。如果重排序之后的执行结果，与按happens-before关系来执行的结果一致，那么这种重排序并不非法（也就是说，JMM允许这种重排序）。

happens-before 给操作限定顺序：
- 根据程序顺序（代码是咋写的）
- 根据监视器锁规则

引入的目的：
- 只要不影响程序的执行结果，编译器和处理器怎么优化都可以
- as-if-serial语义保证单线程内程序的执行结果不被改变，happens-before关系保证正确同步的多线程程序的执行结果不被改变。
- as-if-serial语义和happens-before这么做的目的，都是为了在不改变程序执行结果的前提下，尽可能地提高程序执行的并行度。


# 常见问题
**JMM综述**
对比处理器内存模型和JMM
- 不同的处理器会有不同的内存模型，对不同的操作可能会有不同的重排方法。
- JMM以顺序一致性模型为参考，约束比较强（顺序一致性是最强的约束）。JMM屏蔽了不同处理器内存模型的差异，它在不同的处理器平台之上为Java程序员呈现了一个一致的内存模型。
- JMM是一个语言级的内存模型，处理器内存模型是硬件级的内存模型。

> 由于常见的处理器内存模型比JMM要弱，Java编译器在生成字节码时，会在执行指令序列的适当位置插入内存屏障来限制处理器的重排序。
> 同时，由于各种处理器内存模型的强弱不同，为了在不同的处理器平台向程序员展示一个一致的内存模型，JMM在不同的处理器中需要插入的内存屏障的数量和种类也不相同。

**处理器的缓冲区的影响**
可能出现还没从缓冲区刷新到内存，就从内存读取了
- 写：处理器先写到缓冲区，然后缓冲区刷新到内存
- 读：处理器从内存中读